{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_1 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate1.csv\"\n",
    "plate_1_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate1_repeat.csv\"\n",
    "plate_2_1 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_1.csv\"\n",
    "plate_2_2 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_2.csv\"\n",
    "plate_2_3 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_3.csv\"\n",
    "plate_2_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_repeat.csv\"\n",
    "plate_2_repeat_96 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_repeat _96.csv\"\n",
    "list_A = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listA.csv\"\n",
    "list_A_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listA_repeat.csv\"\n",
    "list_B = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB.csv\"\n",
    "list_B_repeat_end = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB_repeat _end.csv\"\n",
    "list_B_repeat_96 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB_repeat _96.csv\"\n",
    "list_C = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listC.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "from itertools import product\n",
    "\n",
    "# define custom errors\n",
    "class DataError(Exception):\n",
    "    pass\n",
    "\n",
    "class PlateSizeError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "# define well plate dimensions\n",
    "plate_dimensions = {'96':(8, 12), '384':(16, 24)}\n",
    "    \n",
    "    \n",
    "class FA:\n",
    "    \"\"\"Class used for the analysis of fluorescence anisotropy data.\n",
    "    \n",
    "    :param data_dict: A dictionary contaning data frames with pre-processed data and metadata\n",
    "    :type data_dict: dict\n",
    "    :param g_factor: G-factor\n",
    "    :type g_factor: float \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dict, g_factor):\n",
    "        self.data_dict = data_dict\n",
    "        self.g_factor = g_factor\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def read_in_envision(cls, csv_file, data_type='plate', size=384):\n",
    "        \n",
    "        \"\"\"Returns a dictionary of data frames and g-factor needed to construct the class object. \n",
    "        \n",
    "        :param csv_file: File path of the raw data file in .csv format\n",
    "        :type csv_file: str\n",
    "        :param data_type: Format in which the raw data was exported (plate or list), defaults to plate\n",
    "        :type data_type: str\n",
    "        :param size: Size of the well plate (384 or 96), defaults to 384\n",
    "        :type size: int\n",
    "        :return: A dictionary contaning data frames with pre-processed data and g-factor\n",
    "        :rtype: dict, float \"\"\"\n",
    "        \n",
    "        # ensure the plate size is 384 or 96\n",
    "        if str(size) not in plate_dimensions:\n",
    "            raise PlateSizeError('Invalid size of the well plate, should be 384 or 96.')\n",
    "        \n",
    "        # generate a list of well IDs for the pre-processed data frames\n",
    "        row_letters = list(string.ascii_uppercase)[0: plate_dimensions[str(size)][0]]   # generate a list of letters for well IDs\n",
    "        col_numbers = list(np.arange(1, plate_dimensions[str(size)][1] + 1).astype(str))   # generate a list of numbers for well IDs\n",
    "        well_ids = ['%s%s' % (item[0], item[1]) for item in product(row_letters, col_numbers)]\n",
    "        \n",
    "        # try to read in data in plate format\n",
    "        if data_type == 'plate':\n",
    "            try:\n",
    "                data_dict, g_factor = FA.read_in_plate(csv_file, well_ids)\n",
    "                return cls(data_dict, g_factor)\n",
    "            \n",
    "            except (UnboundLocalError, IndexError, ValueError):\n",
    "                raise DataError(f\"Error occured during data read in. Check your file contains data in the 'plate' format and plate size is {size}.\")\n",
    "        \n",
    "        # try to read in data in list format\n",
    "        if data_type == 'list':\n",
    "            try:\n",
    "                data_dict, g_factor = FA.read_in_list(csv_file, well_ids)\n",
    "                return cls(data_dict, g_factor)\n",
    "            \n",
    "            except (UnboundLocalError, IndexError):\n",
    "                raise DataError(\"Error occured during data read in. Check your file contains data in the 'list' format.\")\n",
    "                \n",
    "                \n",
    "    def read_in_plate(csv_file, well_ids):\n",
    "        \n",
    "        \"\"\"Reads the raw data file and finds the information needed to extract data. Passes those parameters to pre_process_plate function and executes it.\n",
    "        Returns a tuple of two elemnts: dictionary of data frames and g-factor.\n",
    "\n",
    "        :param csv_file: File path of the raw data file in .csv format\n",
    "        :type csv_file: str\n",
    "        :param well_ids: A list of well IDs for the pre-processed data frames\n",
    "        :type well_ids: list\n",
    "        :return: A tuple of dictionary of data frames and the g-factor \n",
    "        :rtype: tuple \"\"\"\n",
    "        \n",
    "        with open(csv_file) as file:\n",
    "            all_data_lines = list(csv.reader(file, delimiter=','))   # read the csv file and cast it into a list containing all lines\n",
    "\n",
    "        blank_indexes = list(index for index, item in enumerate(all_data_lines) if item == [])   # list containing indices of all blank rows\n",
    "        blanks = np.array(blank_indexes)   # convert the list of blank indices to a numpy array\n",
    "        read_in_info = []   # list to store the tuples with parameters needed for pandas to read in the csv file\n",
    "\n",
    "        for index, item in enumerate(all_data_lines):   # iterate over all lines in the csv file\n",
    "            if item != [] and re.findall(r\"Plate information\", item[0]) == ['Plate information'] and re.search(r'Results for', all_data_lines[index + 9][0]) == None and re.findall(r\"Formula\", all_data_lines[index+1][10]) != ['Formula']:\n",
    "                skiprows = index + 9   # Set the skiprows parameter for raw data table\n",
    "                skiprows_meta = index + 1   # Set the skiprows parameter for metadata table\n",
    "                end_of_data = blanks[blanks > skiprows].min()   # Calculate the end of data table by finding the smallest blank index after the beginning of data table\n",
    "                read_in_info.append((skiprows, end_of_data - skiprows + 1, skiprows_meta))   # add the skiprows, caculated number of data lines and skiprows for metadata parameters to the list as a tuple\n",
    "                data_format = 'plate1'\n",
    "\n",
    "            if item != [] and re.findall(r\"Plate information\", item[0]) == ['Plate information'] and re.search(r'Results for', all_data_lines[index + 9][0]) != None:\n",
    "                skiprows = index + 10\n",
    "                skiprows_meta = index + 1\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "                read_in_info.append((skiprows, end_of_data - skiprows, skiprows_meta))\n",
    "                data_format = 'plate2'\n",
    "\n",
    "            if item != [] and len(item) > 1 and re.findall(r\"G-factor\", item[0]) == [\"G-factor\"]:\n",
    "                g_factor = float(item[4])   \n",
    "        \n",
    "        return FA.pre_process_plate(csv_file, read_in_info, data_format, well_ids), g_factor\n",
    "\n",
    "    \n",
    "    def pre_process_plate(csv_file, read_in_info, data_format, well_ids):    \n",
    "\n",
    "        \"\"\"Extracts the data and metadata from the csv file, processes it and returns a nested dictionary containing data and metadata for each repeat and channel.\n",
    "\n",
    "        :param csv_file: File path of the raw data file in .csv format\n",
    "        :type csv_file: str\n",
    "        :param read_in_info: Tuples with read in parameters for each channel.\n",
    "        :type read_in_info: list\n",
    "        :param data_format: Plate type (plate1 or plate2)\n",
    "        :type data_format: str\n",
    "        :param well_ids: A list of well IDs for the pre-processed data frames\n",
    "        :type well_ids: list\n",
    "        :return: A dictionary containing data and metadata \n",
    "        :rtype: dict \"\"\" \n",
    "        \n",
    "        data_frames = {}   # dictionary to store data frames\n",
    "        counter = 1   # counter incremented by 0.5 to enable alternating labelling of data frames as 'p' or 's'\n",
    "\n",
    "        for index, item in enumerate(read_in_info):   # iterate over all tuples in the list, each tuple contains skiprows, nrows and skiprows_meta for one channel \n",
    "\n",
    "            if data_format == 'plate1':   # raw data table does not have row and column names so 'names' parameter passed to omit the last column\n",
    "                raw_data = pd.read_csv(csv_file, sep=',', names=col_numbers, index_col=False, engine='python', skiprows=item[0], nrows=item[1], encoding='utf-8')\n",
    "\n",
    "            if data_format == 'plate2':   # raw data table has row and column names, so index_col=0 to set the first column as row labels\n",
    "                raw_data = pd.read_csv(csv_file, sep=',', index_col=0, engine='python', skiprows=item[0], nrows=item[1], encoding='utf-8')\n",
    "                raw_data.drop(raw_data.columns[-1], axis=1, inplace=True)   # delete the last column because it is empty\n",
    "\n",
    "            # generate df for metadata (number of rows of metadata table is always 1) and convert measurement time into datetime object   \n",
    "            metadata = pd.read_csv(csv_file, sep=',', engine='python', skiprows=item[2], nrows=1, encoding='utf-8').astype({'Measurement date': 'datetime64[ns]'})\n",
    "            # convert and reshape data frame into 1D array\n",
    "            data_as_array = np.reshape(raw_data.to_numpy(), (int(well_ids), 1)) \n",
    "\n",
    "            if counter % 1 == 0: \n",
    "                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=['p'])   # generate new 384 (or 96) by 1 data frame with p channel data\n",
    "                data_frames[f'repeat_{int(counter)}'] = {'metadata':metadata, 'data': {'p': new_data, 's':''}}   # add p channel data and metadata dfs to dictionary\n",
    "\n",
    "            if counter % 1 != 0:\n",
    "                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=['s'])   # generate new 384 (or 96) by 1 data frame with s channel data\n",
    "                data_frames[f'repeat_{int(counter-0.5)}']['data']['s'] = new_data   # add s channel data to dictionary\n",
    "\n",
    "            counter = counter + 0.5\n",
    "        \n",
    "        return data_frames\n",
    "\n",
    "\n",
    "    def read_in_list(csv_file, well_ids):\n",
    "\n",
    "        \"\"\"Reads the raw data file and extracts the data and metadata. Passes the raw data to pre_process_list function and executes it.\n",
    "        Returns a tuple of two elemnts: dictionary of data frames and g-factor.\n",
    "\n",
    "        :param csv_file: File path of the raw data file in .csv format\n",
    "        :type csv_file: str\n",
    "        :param well_ids: A list of well IDs for the pre-processed data frames\n",
    "        :type well_ids: list\n",
    "        :return: A tuple of dictionary of data frames and the g-factor\n",
    "        :rtype: tuple \"\"\"\n",
    "\n",
    "        with open(csv_file) as file:  \n",
    "            all_data_lines = list(csv.reader(file, delimiter=',')) # read the csv file and cast it into a list containing all lines\n",
    " \n",
    "        blank_indexes = list(index for index, item in enumerate(all_data_lines) if item == [])   # list containing indexes of all blank rows\n",
    "        blanks = np.array(blank_indexes)   # convert the list of blank indexes to a numpy array\n",
    "        \n",
    "        # set the skiprows to be initially greater than the total number of lines in the file to enable the evaluation of if statement until the 'skiprows' parameter is found\n",
    "        skiprows = len(all_data_lines) + 1\n",
    "        \n",
    "        # iterate over all lines to find beggining of the data table ('skiprows') and determine the format of data  (list A, B, or C)\n",
    "        for index, item in enumerate(all_data_lines):   \n",
    "            if item != [] and len(item) == 1 and re.findall(r\"Plate information\", item[0]) == [\"Plate information\"]:\n",
    "                skiprows_meta = index + 1\n",
    "                end_of_metadata = blanks[blanks > skiprows_meta].min()   # find the end of metadata by finding the smallest blank index after the beginning of metadata\n",
    "                \n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"PlateNumber\", item[0]) == ['PlateNumber'] and re.findall(r\"PlateRepeat\", item[1]) == ['PlateRepeat']:   # find line number with the beggining of the data\n",
    "                skiprows = index - 1\n",
    "                data_format = 'listA'\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "\n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"Plate\", item[0]) == ['Plate'] and re.findall(r\"Barcode\", item[1]) == ['Barcode']:   # find line number with the beggining of the data\n",
    "                skiprows = index\n",
    "                data_format = 'listB'\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "\n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"Plate\", item[0]) == ['Plate']  and re.findall(r\"Well\", item[1]) == ['Well']:\n",
    "                skiprows = index\n",
    "                data_format = 'listC'\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "\n",
    "            if item != [] and re.findall(r\"G-factor\", item[0]) == [\"G-factor\"]:   # find the g factor\n",
    "                g_factor = float(item[4])\n",
    "\n",
    "        nrows = end_of_data - skiprows - 1   # calculate the length of data table\n",
    "        nrows_meta = end_of_metadata - skiprows_meta - 1   # calucalte the length of metadata table (number of rows depends on the number of repeats)\n",
    "\n",
    "        raw_data = pd.read_csv(csv_file, sep=',', engine='python', skiprows=skiprows, nrows=nrows, encoding='utf-8')\n",
    "        raw_metadata = pd.read_csv(csv_file, sep=',', engine='python', skiprows=skiprows_meta, nrows=nrows_meta, encoding='utf-8')\n",
    "\n",
    "        return FA.pre_process_list(raw_data, raw_metadata, data_format, well_ids), g_factor\n",
    "\n",
    "\n",
    "    def pre_process_list(raw_data, raw_metadata, data_format, well_ids):\n",
    "\n",
    "        \"\"\"Extracts the data and metadata for each channel and repeat from the raw data and raw metadata \n",
    "        and returns a nested dictionary containing data and metadata for each repeat and channel.\n",
    "\n",
    "        :param raw_data: Data frame containing raw data\n",
    "        :type raw_data: pandas data frame\n",
    "        :param raw_metadata: Data frame containing raw metadata\n",
    "        :type raw_metadata: pandas data frame\n",
    "        :param data_format: Type of list (listA, listB, or listC)\n",
    "        :type data_format: str\n",
    "        :param well_ids: A list of well IDs for the pre-processed data frames\n",
    "        :type well_ids: list\n",
    "        :return: A dictionary containing data and metadata\n",
    "        :rtype: dict\"\"\"\n",
    "\n",
    "        # remove the '0' from middle position of well numbers (A01 -> A1), done by reassigning the 'Well' column to a Series containing modified well numbers\n",
    "        raw_data['Well'] = raw_data['Well'].apply(lambda x: x[0] + x[2] if x[1] == '0' else x)\n",
    "        \n",
    "        data_frames = {}   # dictionary to store data frames\n",
    "        repeats = list(raw_metadata['Repeat'].to_numpy())   # generate a list with repeats based on the metadata table, e.g. for 3 repeats -> [1,2,3]\n",
    "\n",
    "        for index, repeat in enumerate(repeats):   # iterate over the number of repeats\n",
    "            if data_format == 'listA':\n",
    "                groupped_data = raw_data.groupby(raw_data.PlateRepeat).get_group(repeat)   # group and extract the data by the plate repeat column, i.e. in each iteration get data only for the current repeat \n",
    "\n",
    "                p_groupped = groupped_data.iloc[::3, :]   # extract data only for the p channel, i.e. each third row starting from the first row\n",
    "                s_groupped = groupped_data.iloc[1::3, :]   # extract data only for the s channel, i.e. each third row starting from the second row\n",
    "\n",
    "                p_raw_data = p_groupped[['Well', 'Signal']]   # extract only the two relevant columns\n",
    "                s_raw_data = s_groupped[['Well', 'Signal']]   # for each channel\n",
    "\n",
    "            if data_format in ['listB', 'listC']: \n",
    "                # the column naming is different for the first repeat ('Signal'), then it's 'Signal.1', 'Signal.2', etc.\n",
    "                if repeat == 1: \n",
    "                    p_raw_data = raw_data[['Well', 'Signal']]   \n",
    "                    s_raw_data = raw_data[['Well', f'Signal.{repeat}']]\n",
    "                else:\n",
    "                    p_raw_data = raw_data[['Well', f'Signal.{repeat + index - 1}']]   # the column cotntaining data to be extracted is calculated in each iteration\n",
    "                    s_raw_data = raw_data[['Well', f'Signal.{repeat + index}']]\n",
    "            \n",
    "            # create an empty df with no columns and indexes matching the plate size\n",
    "            indexes = pd.DataFrame(well_ids, columns=['Wells'])\n",
    "            empty_frame = indexes.set_index('Wells')\n",
    "            \n",
    "            p_raw_data.set_index('Well', inplace=True)   # set the row indexes as the well numbers\n",
    "            p_raw_data.set_axis(['p'], axis=1, inplace=True)   # rename the 'Signal' column to 'p'\n",
    "            p_data = empty_frame.join(p_raw_data)   # join the raw data df to an empty frame based on the indexes, assigns 'NaN' to indexes not present in the raw data table\n",
    "            \n",
    "            s_raw_data.set_index('Well', inplace=True)\n",
    "            s_raw_data.set_axis(['s'], axis=1, inplace=True)\n",
    "            s_data = empty_frame.join(s_raw_data)\n",
    "    \n",
    "            metadata = raw_metadata.iloc[[repeat-1]].astype({'Measurement date': 'datetime64[ns]'})   # extract the row with metadata relevant for each repeat and covert date and time into a datetime object\n",
    "            data_frames[f'repeat_{repeat}'] = {'metadata': metadata, 'data': {'p': p_data, 's': s_data}}   # add data frames to the dictionary\n",
    "\n",
    "        return data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = FA.read_in_envision(csv_file=list_A_repeat, data_type='list', size=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.g_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data3 = FA.read_in_envision(csv_file=list_B, data_type='list', size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repeat_1': {'metadata':    Plate  Repeat  Barcode  Measured height  Chamber temperature at start  \\\n",
       "  0      1       1      NaN             14.4                         18.98   \n",
       "  \n",
       "     Chamber temperature at end  Humidity at start  Humidity at end  \\\n",
       "  0                          19               61.5             61.1   \n",
       "  \n",
       "     Ambient temperature at start  Ambient temperature at end  \\\n",
       "  0                         18.98                       19.39   \n",
       "  \n",
       "       Measurement date  Unnamed: 11  \n",
       "  0 2020-11-17 13:30:28          NaN  ,\n",
       "  'data': {'p':                 p\n",
       "   Wells            \n",
       "   A1     18890869.0\n",
       "   A2     27377968.0\n",
       "   A3     15983855.0\n",
       "   A4     21051671.0\n",
       "   A5     22837285.0\n",
       "   ...           ...\n",
       "   H8            NaN\n",
       "   H9            NaN\n",
       "   H10           NaN\n",
       "   H11           NaN\n",
       "   H12           NaN\n",
       "   \n",
       "   [96 rows x 1 columns],\n",
       "   's':                 s\n",
       "   Wells            \n",
       "   A1     20668058.0\n",
       "   A2     29442193.0\n",
       "   A3     18411616.0\n",
       "   A4     23222549.0\n",
       "   A5     25009835.0\n",
       "   ...           ...\n",
       "   H8            NaN\n",
       "   H9            NaN\n",
       "   H10           NaN\n",
       "   H11           NaN\n",
       "   H12           NaN\n",
       "   \n",
       "   [96 rows x 1 columns]}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data3.data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wells</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>20469296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>29296716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>18210982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4</th>\n",
       "      <td>23159988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5</th>\n",
       "      <td>24960618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P20</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P21</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                s\n",
       "Wells            \n",
       "A1     20469296.0\n",
       "A2     29296716.0\n",
       "A3     18210982.0\n",
       "A4     23159988.0\n",
       "A5     24960618.0\n",
       "...           ...\n",
       "P20           NaN\n",
       "P21           NaN\n",
       "P22           NaN\n",
       "P23           NaN\n",
       "P24           NaN\n",
       "\n",
       "[384 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.data_dict['repeat_1']['data']['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data3.g_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wells</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>18890869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>27377968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>15983855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4</th>\n",
       "      <td>21051671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5</th>\n",
       "      <td>22837285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                p\n",
       "Wells            \n",
       "A1     18890869.0\n",
       "A2     27377968.0\n",
       "A3     15983855.0\n",
       "A4     21051671.0\n",
       "A5     22837285.0\n",
       "...           ...\n",
       "H8            NaN\n",
       "H9            NaN\n",
       "H10           NaN\n",
       "H11           NaN\n",
       "H12           NaN\n",
       "\n",
       "[96 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data3.data_dict['repeat_1']['data']['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data2 = FA.read_in_envision(csv_file=list_B_repeat_96, data_type='list', size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.g_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate</th>\n",
       "      <th>Repeat</th>\n",
       "      <th>Barcode</th>\n",
       "      <th>Measured height</th>\n",
       "      <th>Chamber temperature at start</th>\n",
       "      <th>Chamber temperature at end</th>\n",
       "      <th>Humidity at start</th>\n",
       "      <th>Humidity at end</th>\n",
       "      <th>Ambient temperature at start</th>\n",
       "      <th>Ambient temperature at end</th>\n",
       "      <th>Measurement date</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.52</td>\n",
       "      <td>18.78</td>\n",
       "      <td>18.68</td>\n",
       "      <td>61.8</td>\n",
       "      <td>62.3</td>\n",
       "      <td>18.88</td>\n",
       "      <td>18.98</td>\n",
       "      <td>2020-11-17 13:39:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plate  Repeat  Barcode  Measured height  Chamber temperature at start  \\\n",
       "0      1       1      NaN            14.52                         18.78   \n",
       "\n",
       "   Chamber temperature at end  Humidity at start  Humidity at end  \\\n",
       "0                       18.68               61.8             62.3   \n",
       "\n",
       "   Ambient temperature at start  Ambient temperature at end  \\\n",
       "0                         18.88                       18.98   \n",
       "\n",
       "     Measurement date  Unnamed: 11  \n",
       "0 2020-11-17 13:39:13          NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.data_dict['repeat_1']['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wells</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>352962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>357763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>541382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>344433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>431089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C3</th>\n",
       "      <td>302132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              p\n",
       "Wells          \n",
       "A1     352962.0\n",
       "A2     357763.0\n",
       "A3     541382.0\n",
       "A4          NaN\n",
       "A5          NaN\n",
       "A6          NaN\n",
       "A7          NaN\n",
       "A8          NaN\n",
       "A9          NaN\n",
       "A10         NaN\n",
       "A11         NaN\n",
       "A12         NaN\n",
       "B1          NaN\n",
       "B2          NaN\n",
       "B3          NaN\n",
       "B4          NaN\n",
       "B5          NaN\n",
       "B6          NaN\n",
       "B7          NaN\n",
       "B8          NaN\n",
       "B9          NaN\n",
       "B10         NaN\n",
       "B11         NaN\n",
       "B12         NaN\n",
       "C1     344433.0\n",
       "C2     431089.0\n",
       "C3     302132.0\n",
       "C4          NaN\n",
       "C5          NaN\n",
       "C6          NaN\n",
       "C7          NaN\n",
       "C8          NaN\n",
       "C9          NaN\n",
       "C10         NaN\n",
       "C11         NaN\n",
       "C12         NaN\n",
       "D1          NaN\n",
       "D2          NaN\n",
       "D3          NaN\n",
       "D4          NaN\n",
       "D5          NaN\n",
       "D6          NaN\n",
       "D7          NaN\n",
       "D8          NaN\n",
       "D9          NaN\n",
       "D10         NaN\n",
       "D11         NaN\n",
       "D12         NaN\n",
       "E1          NaN\n",
       "E2          NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.data_dict['repeat_2']['data']['p'].iloc[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
