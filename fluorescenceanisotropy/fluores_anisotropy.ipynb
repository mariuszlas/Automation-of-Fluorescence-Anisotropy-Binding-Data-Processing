{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_1 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate1.csv\"\n",
    "plate_1_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate1_repeat.csv\"\n",
    "plate_2_1 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_1.csv\"\n",
    "plate_2_2 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_2.csv\"\n",
    "plate_2_3 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_3.csv\"\n",
    "plate_2_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_repeat.csv\"\n",
    "plate_2_repeat_96 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_repeat _96.csv\"\n",
    "list_A = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listA.csv\"\n",
    "list_A_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listA_repeat.csv\"\n",
    "list_B = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB.csv\"\n",
    "list_B_repeat_end = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB_repeat _end.csv\"\n",
    "list_B_repeat_96 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB_repeat _96.csv\"\n",
    "list_C = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listC.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error(Exception):\n",
    "    pass\n",
    "\n",
    "class DataReadInError(Error):\n",
    "    pass\n",
    "    \n",
    "plate_dimensions = {'96':(8, 12), '384':(16, 24)}\n",
    "    \n",
    "class FA:\n",
    "    \"\"\"\n",
    "    :param csv_file: Raw data file in csv format.\n",
    "    :param type: str\n",
    "    :param read_in_info: Information needed to pre-process the data.\n",
    "    :param type: Varies with the data format. Check the appropriate read in function.\n",
    "    :param g_factor: G-factor.\n",
    "    :param type: float\n",
    "    :param data_format: Format in which the raw data was exported (plate1, plate2, listA, listB or listC).\n",
    "    :param type: str \n",
    "    :param wells: Number of wells on the plate.\n",
    "    :param type: int   \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, read_in_info, g_factor, data_format, wells):\n",
    "        self.csv_file = csv_file\n",
    "        self.read_in_info = read_in_info\n",
    "        self.g_factor = g_factor\n",
    "        self.data_format = data_format\n",
    "        self.wells = wells\n",
    "        \n",
    "        if data_format in ['plate1', 'plate2']:\n",
    "            self.data_dict = self.pre_process_plate(self.csv_file, self.read_in_info, self.data_format, self.wells)\n",
    "        if data_format in ['listA', 'listB', 'listC']:\n",
    "            self.data_dict = self.pre_process_list(self.read_in_info, self.data_format)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def read_in_plate(cls, csv_file, wells):\n",
    "\n",
    "        \"\"\" Iterates over the raw data file to find the line numbers at which the metadata table and raw data table begin for \n",
    "        each channel and reapeat. Calculates the length of those tables. Finds the G-factor. Determines the format of data (plate 1 or 2).\n",
    "\n",
    "        :param csv_file: Raw data file in csv format.\n",
    "        :param type: str\n",
    "        :param wells: Number of wells on the plate.\n",
    "        :param type: int\n",
    "        :return: read_in_info is a list of tuples (one tuple for each channel) with parameters needed for pandas to read in the csv file. \"\"\"\n",
    "\n",
    "        with open(csv_file) as file:\n",
    "            all_data_lines = list(csv.reader(file, delimiter=','))   # read the csv file and cast it into a list containing all lines\n",
    "\n",
    "        blank_indices = list(index for index, item in enumerate(all_data_lines) if item == [])   # list containing indices of all blank rows\n",
    "        blanks = np.array(blank_indices)   # convert the list of blank indices to a numpy array\n",
    "        read_in_info = []   # list to store the tuples with parameters needed for pandas to read in the csv file\n",
    "\n",
    "        for index, item in enumerate(all_data_lines):   # iterate over all lines in the csv file\n",
    "            if item != [] and re.findall(r\"Plate information\", item[0]) == ['Plate information'] and re.search(r'Results for', all_data_lines[index + 9][0]) == None and re.findall(r\"Formula\", all_data_lines[index+1][10]) != ['Formula']:\n",
    "                skiprows = index + 9   # Set the skiprows parameter for raw data table\n",
    "                skiprows_meta = index + 1   # Set the skiprows parameter for metadata table\n",
    "                end_of_data = blanks[blanks > skiprows].min()   # Calculate the end of data table by finding the smallest blank index after the beginning of data table\n",
    "                read_in_info.append((skiprows, end_of_data - skiprows + 1, skiprows_meta))   # add the skiprows, caculated number of data lines and skiprows for metadata parameters to the list as a tuple\n",
    "                data_format = 'plate1'\n",
    "\n",
    "            if item != [] and re.findall(r\"Plate information\", item[0]) == ['Plate information'] and re.search(r'Results for', all_data_lines[index + 9][0]) != None:\n",
    "                skiprows = index + 10\n",
    "                skiprows_meta = index + 1\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "                read_in_info.append((skiprows, end_of_data - skiprows, skiprows_meta))\n",
    "                data_format = 'plate2'\n",
    "\n",
    "            if item != [] and len(item) > 1 and re.findall(r\"G-factor\", item[0]) == [\"G-factor\"]:\n",
    "                g_factor = float(item[4])   \n",
    "\n",
    "        return cls(csv_file, read_in_info, g_factor, data_format, wells)\n",
    "\n",
    "\n",
    "    def pre_process_plate(self, csv_file, read_in_info, data_format, wells):    \n",
    "\n",
    "        \"\"\" Iterates over the raw data file and creates data frames for the data and metadata for each channel, converts them into\n",
    "        a 384 or 96 by 1 format and adds them into a dictionary.\n",
    "\n",
    "        :param csv file: Raw data file in csv format.\n",
    "        :param type: str\n",
    "        :param read_in_info: A list containg tuples with read in parameters for each channel.\n",
    "        :param type: list\n",
    "        :param data_format: Type of plate (plate1 or plate2).\n",
    "        :param type: str\n",
    "        :param wells: Number of wells on the plate.\n",
    "        :param type: int\n",
    "        :return: A dictionary containg a dictionary for each repeat containg the metadata df and a dictionary with s and p channel dfs. \"\"\" \n",
    "        \n",
    "        row_letters = list(string.ascii_uppercase)[0:plate_dimensions[str(wells)][0]]   # generate a list of letters for well IDs\n",
    "        col_numbers = list(np.arange(1, plate_dimensions[str(wells)][1]+1).astype(str))   # generate a list of numbers for well IDs\n",
    "        well_ids = ['%s%s' % (item[0], item[1]) for item in product(row_letters, col_numbers)]   # generate a list of well IDs for the data table\n",
    "\n",
    "        data_frames = {}   # dictionary to store the data frames\n",
    "        counter = 1   # counter incremented by 0.5 to enable alternating labelling of data frames as p or s\n",
    "\n",
    "        for index, item in enumerate(read_in_info):   # iterate over each tuple in the list\n",
    "\n",
    "            if data_format == 'plate1':   # raw data table does not have row and column names so 'names' parameter passed to omit the last column\n",
    "                raw_data = pd.read_csv(csv_file, sep=',', names=col_numbers, index_col=False, engine='python', skiprows=item[0], nrows=item[1], encoding='utf-8')\n",
    "\n",
    "            if data_format == 'plate2':   # raw data table has row an column names, so 'index_col' is 0 to set the first column as row labels\n",
    "                raw_data = pd.read_csv(csv_file, sep=',', index_col=0, engine='python', skiprows=item[0], nrows=item[1], encoding='utf-8')\n",
    "                raw_data.drop(raw_data.columns[-1], axis=1, inplace=True)   # delete the last column because it is empty\n",
    "\n",
    "            # generate df for metadata (number of rows is always 1) and convert measurement time into datetime object   \n",
    "            metadata = pd.read_csv(csv_file, sep=',', engine='python', skiprows=item[2], nrows=1, encoding='utf-8').astype({'Measurement date': 'datetime64[ns]'})\n",
    "            data_as_array = np.reshape(raw_data.to_numpy(), (int(wells), 1))   # convert data frames to numpy arrays and reshape into 1D array\n",
    "\n",
    "            if counter % 1 == 0: \n",
    "                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=['p'])   # generate new 384 (or 96) by 1 data frame with p channel data\n",
    "                data_frames[f'repeat_{int(counter)}'] = {'metadata':metadata, 'data': {'p': new_data, 's':''}}   # add data and metadata dfs to the dictionary\n",
    "\n",
    "            if counter % 1 != 0:\n",
    "                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=['s'])   # generate new 384 (or 96) by 1 data frame with s channel data\n",
    "                data_frames[f'repeat_{int(counter-0.5)}']['data']['s'] = new_data\n",
    "\n",
    "            counter = counter + 0.5\n",
    "\n",
    "        return data_frames\n",
    "\n",
    "    @classmethod\n",
    "    def read_in_list(cls, csv_file, wells):\n",
    "\n",
    "        \"\"\" Iterates over the csv file to find  the line numbers at which the metadata table and raw data table\n",
    "        begin. Creates two pandas data frames: for the raw data and metadata.\n",
    "\n",
    "        :param csv_file: Raw data file in csv format.\n",
    "        :param type: str\n",
    "        :param wells: Number of wells on the plate.\n",
    "        :param type: int\n",
    "        :return: A tuple with raw data and metadata dfs.\"\"\"\n",
    "\n",
    "        with open(csv_file) as file:  \n",
    "            all_data_lines = list(csv.reader(file, delimiter=',')) # read the csv file and cast it into a list containing all lines\n",
    "\n",
    "        # set the skiprows to be initially greater than the total number of lines in the files to enable the evaluation of if statement until the 'skiprows' parameter is found\n",
    "        skiprows = len(all_data_lines) + 1 \n",
    "        # list containing indices of all blank rows\n",
    "        blank_indices = list(index for index, item in enumerate(all_data_lines) if item == [])   # list containing indices of all blank rows\n",
    "        blanks = np.array(blank_indices)   # convert the list of blank indices to a numpy array\n",
    "\n",
    "        # iterate over all lines to find beggining of the data table ('skiprows') and determine the format of data  (list A, B, or C)\n",
    "        for index, item in enumerate(all_data_lines):   \n",
    "            if item != [] and len(item) == 1 and re.findall(r\"Plate information\", item[0]) == [\"Plate information\"]:\n",
    "                skiprows_meta = index + 1\n",
    "                end_of_metadata = blanks[blanks > skiprows_meta].min()   # find the end of metadata by finding the smallest blank index after the beginning of metadata\n",
    "                nrows_meta = end_of_metadata - skiprows_meta - 1   # calucalte the length of metadata table (the number f rows depends on the number of repeats)\n",
    "\n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"PlateNumber\", item[0]) == ['PlateNumber'] and re.findall(r\"PlateRepeat\", item[1]) == ['PlateRepeat']:   # find line number with the beggining of the data\n",
    "                skiprows = index - 1\n",
    "                data_format = 'listA'\n",
    "\n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"Plate\", item[0]) == ['Plate'] and re.findall(r\"Barcode\", item[1]) == ['Barcode']:   # find line number with the beggining of the data\n",
    "                skiprows = index\n",
    "                data_format = 'listB'\n",
    "\n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"Plate\", item[0]) == ['Plate']  and re.findall(r\"Well\", item[1]) == ['Well']:\n",
    "                skiprows = index\n",
    "                data_format = 'listC'\n",
    "\n",
    "            if item != [] and re.findall(r\"G-factor\", item[0]) == [\"G-factor\"]:   # find the g factor\n",
    "                g_factor = float(item[4])\n",
    "\n",
    "            # find the index of the first blank row after the data table i.e. the end of data table and break out of the loop\n",
    "            if item == [] and index > skiprows:   \n",
    "                end_of_data = index\n",
    "                break  \n",
    "\n",
    "        nrows = end_of_data - skiprows - 1   # calculate the length of data table\n",
    "\n",
    "        raw_data = pd.read_csv(csv_file, sep=',', engine='python', skiprows=skiprows, nrows=nrows, encoding='utf-8')\n",
    "        metadata = pd.read_csv(csv_file, sep=',', engine='python', skiprows=skiprows_meta, nrows=nrows_meta, encoding='utf-8')\n",
    "\n",
    "        return cls(csv_file, (raw_data, metadata), g_factor, data_format, wells)\n",
    "\n",
    "\n",
    "    def pre_process_list(self, read_in_info, data_format):\n",
    "\n",
    "        \"\"\"Extracts the data for each channel and repeat from the raw data table and adds to a dictionary.\n",
    "\n",
    "        :param  read_in_info: A tuple containing data frames for raw data and metadata.string representing type of list (A, B, or C).\n",
    "        :param type: tuple\n",
    "        :param data_format: Type of list (A, B, or C).\n",
    "        :param type: str\n",
    "        :return: A dictionary containg a dictionary for each repeat containg the metadata df and a dictionary with s and p channel dfs.\"\"\"\n",
    "\n",
    "        data_frames = {}   # dictionary to store data frames\n",
    "        repeats = list(read_in_info[1]['Repeat'].to_numpy())   # generate a list with repeats based on the metadata table, e.g. for 3 repeats -> [1,2,3]\n",
    "\n",
    "        # remove the '0' from middle position of well numbers (A01 -> A1), done by reassigning the 'Well' column to a Series containing modified well numbers\n",
    "        read_in_info[0]['Well'] = read_in_info[0]['Well'].apply(lambda x: x[0] + x[2] if x[1] == '0' else x)\n",
    "\n",
    "        for index, repeat in enumerate(repeats):   # iterate over the number of repeats\n",
    "            if data_format == 'listA':\n",
    "                groupped_data = read_in_info[0].groupby(read_in_info[0].PlateRepeat).get_group(repeat)   # group and extract the data by the plate repeat column, i.e. in each iteration get data only for the current repeat \n",
    "\n",
    "                p_groupped = groupped_data.iloc[::3, :]   # extract data only for the p channel, i.e. each third row starting from the first row\n",
    "                s_groupped = groupped_data.iloc[1::3, :]   # extract data only for the s channel, i.e. each third row starting from the second row\n",
    "\n",
    "                p_raw = p_groupped[['Well', 'Signal']]   # extract only the two relevant columns\n",
    "                s_raw = s_groupped[['Well', 'Signal']]   # for each channel\n",
    "\n",
    "            if data_format in ['listB', 'listC']: \n",
    "                # the column naming is different for the first repeat, i.e. just 'Signal', then it's 'Signal.1', 'Signal.2', etc.\n",
    "                if repeat == 1: \n",
    "                    p_raw = read_in_info[0][['Well', 'Signal']]   \n",
    "                    s_raw = read_in_info[0][['Well', f'Signal.{repeat}']]\n",
    "                else:\n",
    "                    p_raw = read_in_info[0][['Well', f'Signal.{repeat + index - 1}']]   # the column to be extracted is calculated in each iteration\n",
    "                    s_raw = read_in_info[0][['Well', f'Signal.{repeat + index}']]\n",
    "\n",
    "            # set row indices as the well numbers and rename the 'Signal' column to 'p' or 's'\n",
    "            p_raw.set_index('Well', inplace=True)\n",
    "            p_raw.set_axis(['p'], axis=1, inplace=True)\n",
    "            s_raw.set_index('Well', inplace=True)\n",
    "            s_raw.set_axis(['s'], axis=1, inplace=True)\n",
    "\n",
    "            meta = read_in_info[1].iloc[[repeat-1]].astype({'Measurement date': 'datetime64[ns]'})   # extract the row with metadata relevant for each repeat and covert date and time into a datetime object\n",
    "            data_frames[f'repeat_{repeat}'] = {'metadata': meta, 'data': {'p': p_raw, 's':s_raw}}   # add data frames to the dictionary\n",
    "\n",
    "        return data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = FA.read_in_list(list_A_repeat, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.g_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'listA'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Well</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>20469296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>29296716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>18210982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4</th>\n",
       "      <td>23159988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5</th>\n",
       "      <td>24960618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K20</th>\n",
       "      <td>26376527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K21</th>\n",
       "      <td>11347544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K22</th>\n",
       "      <td>8781580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K23</th>\n",
       "      <td>14211858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K24</th>\n",
       "      <td>13945420.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               s\n",
       "Well            \n",
       "A1    20469296.0\n",
       "A2    29296716.0\n",
       "A3    18210982.0\n",
       "A4    23159988.0\n",
       "A5    24960618.0\n",
       "...          ...\n",
       "K20   26376527.0\n",
       "K21   11347544.0\n",
       "K22    8781580.0\n",
       "K23   14211858.0\n",
       "K24   13945420.0\n",
       "\n",
       "[144 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.data_dict['repeat_1']['data']['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data2 = FA.read_in_plate(plate_1_repeat, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.g_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plate1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate</th>\n",
       "      <th>Repeat</th>\n",
       "      <th>Barcode</th>\n",
       "      <th>Measured height</th>\n",
       "      <th>Chamber temperature at start</th>\n",
       "      <th>Chamber temperature at end</th>\n",
       "      <th>Humidity at start</th>\n",
       "      <th>Humidity at end</th>\n",
       "      <th>Ambient temperature at start</th>\n",
       "      <th>Ambient temperature at end</th>\n",
       "      <th>Group</th>\n",
       "      <th>Label</th>\n",
       "      <th>ScanX</th>\n",
       "      <th>ScanY</th>\n",
       "      <th>Measinfo</th>\n",
       "      <th>Kinetics</th>\n",
       "      <th>Measurement date</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.4</td>\n",
       "      <td>18.98</td>\n",
       "      <td>18.8</td>\n",
       "      <td>61.7</td>\n",
       "      <td>61.5</td>\n",
       "      <td>18.98</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1</td>\n",
       "      <td>Copy of Kris FP Fluorescein anisotropy(1)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>De=1st Ex=Top Em=Top Wdw=N/A (15)</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-17 13:33:43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plate  Repeat  Barcode  Measured height  Chamber temperature at start  \\\n",
       "0      1       1      NaN             14.4                         18.98   \n",
       "\n",
       "   Chamber temperature at end  Humidity at start  Humidity at end  \\\n",
       "0                        18.8               61.7             61.5   \n",
       "\n",
       "   Ambient temperature at start  Ambient temperature at end  Group  \\\n",
       "0                         18.98                        18.9      1   \n",
       "\n",
       "                                       Label  ScanX  ScanY  \\\n",
       "0  Copy of Kris FP Fluorescein anisotropy(1)      0      0   \n",
       "\n",
       "                            Measinfo  Kinetics    Measurement date  \\\n",
       "0  De=1st Ex=Top Em=Top Wdw=N/A (15)         0 2020-11-17 13:33:43   \n",
       "\n",
       "   Unnamed: 17  \n",
       "0          NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.data_dict['repeat_1']['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>18964719.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>27435568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>16237095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4</th>\n",
       "      <td>21291729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5</th>\n",
       "      <td>22591167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P20</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P21</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              p\n",
       "A1   18964719.0\n",
       "A2   27435568.0\n",
       "A3   16237095.0\n",
       "A4   21291729.0\n",
       "A5   22591167.0\n",
       "..          ...\n",
       "P20         NaN\n",
       "P21         NaN\n",
       "P22         NaN\n",
       "P23         NaN\n",
       "P24         NaN\n",
       "\n",
       "[384 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.data_dict['repeat_2']['data']['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
